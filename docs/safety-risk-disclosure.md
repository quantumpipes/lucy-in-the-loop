## Safety & Risk Disclosure

**Important:** Lucy in the Loop is an AI-based companion designed to support mental well-being and performance. **It is *not* a licensed medical or mental health professional.** The system can provide guidance, coping strategies, and coaching based on therapeutic principles, but it **does not replace professional therapy or medical treatment**. Please read the following disclosures carefully to understand the scope and limitations of Lucy’s support.

### Not a Substitute for Human Care

Lucy is **not a substitute for professional mental health services**. While it strives to offer helpful and evidence-based advice, it cannot replicate the judgment of a trained clinician. The effectiveness of Lucy’s guidance depends on the quality of its algorithms and data, which, despite continuous improvement, have limitations. You should not disregard or delay seeking professional advice because of something you read or were told by Lucy. If you are in therapy or under medical care, think of Lucy as a supplemental tool – like a journal or self-help workbook – rather than your primary source of care.

### Crisis Situations

Lucy in the Loop **is not equipped to handle emergency situations** or crises by itself. If you are experiencing severe distress, suicidal thoughts, or any psychiatric emergency, **you should immediately contact a mental health professional or emergency services.** Lucy does include a **Safety Agent** that continuously monitors for signs of crisis (for example, language indicating suicidal ideation) with high accuracy. If it detects you may be in danger, it will respond with safety measures – such as encouraging you to reach out to a trusted person or providing the number for a crisis hotline. However, Lucy **cannot call emergency services on your behalf** and cannot physically intervene. It can only urge you to seek help and, if configured, alert a pre-designated emergency contact or clinician (this latter feature requires opt-in and setup, and even then, works offline via perhaps a local SMS if available, which most users won’t configure). In short, while Lucy will try to help in a crisis, **it does not guarantee intervention**, so you must take action to get human help.

Always have a plan for emergencies. We recommend users keep contact information for local emergency services or crisis hotlines readily available. Lucy’s Safety Agent is meant to complement, not replace, your personal safety plan.

### Accuracy and Reliability

Artificial intelligence is not infallible. Lucy draws on advanced language models and curated mental health knowledge to provide responses, but there are risks of mistakes or misunderstood context:

* **Inaccurate or Incomplete Advice:** Lucy might occasionally give advice or information that is *incorrect, outdated, or not fully applicable* to your situation. For instance, it might misinterpret what you’ve said due to ambiguity, or its suggested exercise might not be effective for you. We strive for high quality – Lucy’s knowledge base is updated with thousands of research papers and it undergoes testing – but no AI can guarantee 100% accurate outputs. Users should use their own judgment and, when in doubt, double-check important advice with a professional or credible source.
* **Limited Understanding:** Lucy tries to understand context and nuances, but it has a limited perspective (it does not truly “know” you like a person would). It may sometimes offer responses that feel generic or slightly off-target if it hasn’t gathered enough context. It might also struggle with sarcasm, metaphor, or language quirks at times. We continuously improve the conversation agent, but misunderstandings can occur. If Lucy’s response doesn’t make sense or misses your point, you may need to clarify or rephrase your input.
* **Bias and Fairness:** The AI models are trained on large datasets and could inadvertently reflect biases present in those data. We have implemented filters and an **Ethics Engine** to reduce biased or harmful outputs, and we are committed to impartial, culturally sensitive support. However, if you ever feel that Lucy’s response is biased or inappropriate, please report it. Using user feedback, we will fine-tune the system to address any bias issues.

### Appropriate Use

* **Scope of Issues:** Lucy is designed to assist with *mild to moderate* mental health concerns (like stress, anxiety, goal-setting, mood tracking) and general well-being coaching. It can also help you practice therapeutic techniques (like a CBT thought challenge) or provide motivational support. It is **not suited for severe mental illnesses** that require intensive treatment (for example, it cannot manage active psychotic symptoms, and it is not a medical device for conditions like severe depression requiring medication). Those conditions should be managed by qualified professionals, with Lucy at most as a supplemental aid if your provider deems it appropriate.
* **Ages:** Lucy in the Loop is intended for use by adults. It is not designed or vetted for use by children under 13. Adolescents 13–17 should only use it with parental consent and awareness, and ideally with guidance from a clinician, given the sensitivity of mental health in younger populations. (We follow guidelines that AI mental health tools should include disclaimers for young users that they are not a substitute for professional help.)
* **User Responsibility:** Using Lucy is ultimately *your* choice and responsibility. You are in control – you can stop using it at any time, ignore its advice, or seek a second opinion. We encourage you to treat Lucy’s suggestions as you would self-help book advice: potentially useful, but to be evaluated and adapted to your own situation. Always prioritize your well-being and do not solely rely on any AI if you feel worse or if something isn’t helping.

### Ethical and Privacy Considerations

* **Privacy Risks:** While Lucy is offline and privacy-focused, if you choose to share any output or use it in a public manner (for example, copy-pasting a conversation to social media), be mindful that you could expose personal data. The privacy protections hold when you keep your data within Lucy; we are not responsible for data you choose to expose. Also, ensure your device itself is secure (with a password, encryption, etc.) to protect Lucy’s local data. If others have access to your device, they might access your Lucy conversations unless you’ve taken steps to segregate or protect that data.
* **AI Autonomy Risks:** Lucy operates largely autonomously. While this means it can improve and function without much human input, it also means some decisions about what content it shows you or what fixes it applies happen without you. We have **extensive safeguards** (as detailed in the Safety Policies and Transparent Autonomy sections) to prevent any autonomous action from causing harm. However, there’s always a small risk with autonomous systems. For example, an autonomous update might introduce a bug that affects how Lucy interacts with you. We mitigate this through rigorous testing and the ability to rollback changes. As a user, staying aware of updates and reading our release notes can help you understand changes in Lucy’s behavior. If you ever suspect Lucy’s autonomy is leading it astray (e.g., it’s behaving oddly after an update), you can use the kill switch or simply restart it in a safe mode and report the issue.

### Consent and Agreement

By using Lucy in the Loop, you acknowledge that you understand these limitations and risks. When you first start Lucy, it will present you with this Safety & Risk Disclosure (along with the Privacy Policy and Terms of Use) and ask you to agree before proceeding. We encourage you to periodically review these disclosures, as we will update them as the system evolves (especially as autonomy increases).

**Remember:** Lucy is a tool – a very advanced and caring one, but a tool nonetheless. It works best as an addition to your wellness toolbox alongside other supports (friends, family, hobbies, professionals). Always take care of yourself and seek human help when needed. Lucy’s goal is to empower you, not to create dependence or replace human connection.

If you have any questions or concerns about the information in this Safety & Risk Disclosure, please contact us through the project’s support channels. Your well-being and trust are our top priorities, and we are continually working to make Lucy as safe, ethical, and effective as possible.

*(In case of an emergency, do not wait—contact a mental health professional or emergency service immediately.)*
